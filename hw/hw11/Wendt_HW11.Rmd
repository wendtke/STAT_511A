---
title: "STAT 511A Homework 11"
author: "Kathleen Wendt"
date: "12/09/2019"
output:
  pdf_document: default
---

```{r packages, include = FALSE}
library(readxl)
library(janitor)
library(tidyverse)
library(broom)
library(car)
library(kableExtra)
```

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 6, 
                      fig.height = 4, 
                      fig.path = "figs/",
                      echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE)
```

# Question 1: Running

Review problem 11.22 from Ott & Longnecker regarding treadmill “time to exhaustion” (X) and 10km race times (Y).

```{r run_data}
run_data <- readxl::read_xlsx("data/ex11-22.xlsx") %>% 
  janitor::clean_names() %>% 
  dplyr::rename("race_time" = "x10_k")
```

## Part 1A: Linear Regression

Regress 10.K (Y) on Treadmill (X) and include the “summary” information in your assignment.

```{r run_fit}
run_lm <- lm(race_time ~ treadmill, data = run_data)
summary(run_lm)
```

\pagebreak

## Part 1B: Scatterplot

Create a scatterplot of 10-K vs Treadmill with fitted regression line overlaid.

```{r run_plot}
run_data %>% 
  ggplot(aes(x = treadmill, y = race_time)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Treadmill Time to Exhaustion") + 
  ylab("10 km Race Times (min)") + 
  ggtitle("Association between Time to Exhaustion and Race Times") +
  theme_minimal() 
```

## Part 1C: Slope

Give the estimate, 95% confidence interval and interpretation of the slope. (4 pts)

```{r tidy_run_fit}
tidy_run_lm <- broom::tidy(run_lm)
```

### Estimate

The estimate for the slope is `r tidy_run_lm$estimate[2]`.

### 95% Confidence Interval 

```{r run_slope_ci}
tidy_run_slope_ci <- broom::tidy(confint(run_lm, level = 0.95)) %>% 
  janitor::clean_names() %>% 
  dplyr::filter(rownames == "treadmill")
```

The 95% confidence interval for the slope is (`r tidy_run_slope_ci[2]`, `r tidy_run_slope_ci[3]`).

### Interpretation

A difference of a one unit increase in treadmill time to exhaustion is, on average, associated with a `r tidy_run_lm$estimate[2]` minute decrease in 10 km race time in this sample. There is a negative, linear association between treadmill time to exhaustion and 10 km race time.

## Part 1D: R-squared

Give the $R^2$ value and interpretation in terms of this scenario.

$R^2$ = 0.6807

### Interpretation

68% of the variance in 10 km run times can be attributed to the model relating treadmill time to exhaustion and 10 km run times.

## Part 1E: Prediction

Give the predicted 10.K time for a runner with Treadmill = 11. 

```{r run_predict}
runner <- dplyr::tibble(treadmill = 11)
runner_pred <- broom::tidy(predict(object = run_lm,
                                   runner,
                                   interval = "confidence"))
```

`r runner_pred$fit` minutes

Also provide a corresponding prediction interval.

(`r runner_pred$lwr`, `r runner_pred$upr`)

## Part 1F: Assumptions

Create the plots of (1) residuals vs fitted values and (2) qqplot of residuals.

```{r run_res}
run_res_fit <- dplyr::tibble(res = residuals(run_lm),
                             fit = fitted(run_lm))

run_res_fit %>%
  ggplot(aes(x = fit, y = res)) +
  geom_point() +
  xlab("Fitted Values") + 
  ylab("Residuals") +
  ggtitle("Residual Plot for Run Data") +
  theme_minimal()
```

```{r run_qq}
run_data %>% 
  ggplot(aes(sample = residuals(run_lm))) + 
  geom_qq() +
  geom_qq_line(aes(sample = residuals(run_lm)), 
               col = "red") +
  labs(title = "Normal QQ Plot for Run Data",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()
```

## Part 1G: Outlier

Based on the plots above, subject 13 appears to be a bit of an outlier. Run a formal outlier test for this observation. Provide the p-value and make a conclusion. Note that since we identified this observation after looking at the data, a Bonferonni adjustment is appropriate.

```{r run_outlier}
run_outlier <- car::outlierTest(run_lm)
```

Using `car::outlierTest` to identify the observation with the most extreme residual, the Bonferonni p-value for observation 13 is `r run_outlier$bonf.p` > $\alpha$ = 0.05. Based on this, we fail to reject the null hypothesis that observation 13 is NOT an outlier.

\pagebreak

# Question 2: Steel 

Data on age in coating Thickness (X) and Strength (Y) from an experiment involving steel are available from Canvas as Steel.csv.

```{r steel_data}
steel_data <- readr::read_csv("data/Steel.csv") %>% 
  janitor::clean_names()
```

## Part 2A

Regress Strength (Y) against Thick (X) and look at 
(1) the plot of Strength versus Thick 
(2) residuals versus predicted values and 
(3) qqplot of residuals. 
Include these plots in your assignment. 
Do the regression assumptions appear to be met? Discuss. (4 pts)

### Steel Data

```{r steel_plot}
steel_data %>%
  ggplot(aes(x = thick, y = strength)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Steel Thickness") +
  ylab("Steel Strength") +
  ggtitle("Association between Steel Thickness and Strength") +
  theme_minimal()
```

### Linear Regression

```{r steel_lm}
steel_lm <- lm(formula = strength ~ thick, data = steel_data)
summary(steel_lm)
```

### Check Assumptions

```{r steel_res}
steel_res_fit <- dplyr::tibble(res = residuals(steel_lm),
                               fit = fitted(steel_lm))

steel_res_fit %>%
  ggplot(aes(x = fit, y = res)) +
  geom_point() +
  xlab("Fitted Values") + 
  ylab("Residuals") +
  ggtitle("Residual Plot for Steel Data") +
  theme_minimal()
```

```{r steel_qq}
steel_data %>% 
  ggplot(aes(sample = residuals(steel_lm))) + 
  geom_qq() +
  geom_qq_line(aes(sample = residuals(steel_lm)), 
               col = "red") +
  labs(title = "Normal QQ Plot for Steel Data",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()
```

Based on the above plots and additional histograms, there is evidence against the assumptions for simple linear regression. Specifically, the assumption of linearity is challenged by the curvilinear/quadratic "trend" in the plot of residual vs. fitted values. Furthermore, the assumption of equal variances is challenged by the "categorical" pattern in the first plot. Regarding the Q-Q plot to assess normality of residuals, there is some evidence for heavy tails and against the assumption of normality. A simple linear regression is not an appropriate analytic technique for these data.

## Part 2B: F-test for Fit

Perform an F-test for “lack of fit”. Give your p-value and make a conclusion. (4 pts)

```{r steel_anova}
steel_lm_fac <- lm(strength ~ as.factor(thick),
                  data = steel_data)
```

```{r steel_ftest}
steel_ftest <- anova(steel_lm, steel_lm_fac)
steel_ftest
```

```{r steel_ftest_tidy}
tidy_ftest <- broom::tidy(steel_ftest)
```

We reject the null hypothesis that the linear regression model is appropriate, p = `r tidy_ftest$p.value[2]` < $\alpha$ = 0.05. 

## Part 2C

Now perform a quadratic regression and create a scatterplot with the fitted curve overlaid. Include the “summary” table and plot in your assignment. This can be done with code like the following. Note that b0,b1,b2 need to be replaced with estimates from the quadratic regression. (4 pts)

```{r thick2}
steel_data <- steel_data %>% 
  dplyr::mutate(thick2 = thick^2)
```

```{r steel_quad}
steel_lm_quad <- lm(strength ~ thick + thick2, data = steel_data)
summary(steel_lm_quad)
```

```{r steel_quad_plot}
steel_g <- ggplot(steel_data) +
  geom_point(aes(x = thick, y = strength)) +
  labs(x = "Steel Thickness",
       y = "Steel Strength") +
  ggtitle("Quadratic Relationship between Steel Thickness and Strength")

steel_g +
  geom_abline(aes(slope = coef(steel_lm )[2],
                  intercept = coef(steel_lm )[1])) +
  geom_line(aes(x = thick, y = fitted(steel_lm_quad)), col = "blue") +
  theme_minimal()
```

\pagebreak

# Question 3

```{r sat_data}
sat_data <- readxl::read_xlsx("data/ex11-50.xlsx") %>% 
  janitor::clean_names() %>% 
  dplyr::rename(year = gender_type)
```

Review problem 11.50 from Ott & Longnecker regarding SAT Scores. 

## Part 3A

Create pairwise scatterplots for all 4 variables (Male.Verbal, Female.Verbal, Male.Math, Female.Math)

```{r sat_plots}
sat_data %>% 
  dplyr::select(-year) %>% 
  pairs()
```

## Part 3B

Calculate pairwise (Pearson) correlations for all 4 variables. Which pair of variables has the strongest correlation? (4 pts)

```{r sat_corr}
kableExtra::kable(sat_data %>%
                    dplyr::select(-year) %>%
                    corrr::correlate(method = "pearson"))
```

`male_math`/`female_math` pair has the highest correlation (0.98).

## Part 3C

Provide a test of the correlation for Female.Verbal vs Female.Math. Give the p-value and conclusion in your assignment.

```{r}
sat_cor_test <- broom::tidy(cor.test(sat_data$female_verbal,
                                     sat_data$female_math))
```

The above correlation test between `female_verbal` and `female_math` yielded a p-value of `r sat_cor_test$p.value`, which is higher than $\alpha$ = 0.05. There is no evidence to suggest a significant relationship between female verbal and female math scores.
